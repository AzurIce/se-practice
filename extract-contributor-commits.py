#!/usr/bin/env python3
"""
æå–æ¯ä¸ªä»“åº“çš„è´¡çŒ®è€… commit æ•°æ®
"""
import json
import subprocess
from pathlib import Path
from datetime import datetime
from collections import defaultdict

def get_commits(repo_path: Path, branch: str) -> list:
    """è·å–ä»“åº“çš„æ‰€æœ‰ commit ä¿¡æ¯"""
    try:
        # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯
        subprocess.run(
            ["git", "checkout", branch],
            cwd=repo_path,
            capture_output=True,
            check=True
        )
        
        # è·å– commit ä¿¡æ¯ï¼šä½œè€…åã€æ—¥æœŸã€commit æ ‡é¢˜
        result = subprocess.run(
            [
                "git", "log",
                "--all",
                "--format=%an|%ai|%s"
            ],
            cwd=repo_path,
            capture_output=True,
            text=True,
            check=True
        )
        
        commits = []
        for line in result.stdout.strip().split('\n'):
            if line:
                parts = line.split('|', 2)
                if len(parts) == 3:
                    author, date_str, title = parts
                    # è§£ææ—¥æœŸå¹¶æ ¼å¼åŒ–ä¸º YYYY-MM-DD
                    date = datetime.fromisoformat(date_str.replace(' +', '+').replace(' -', '-'))
                    commits.append({
                        "author": author.strip(),
                        "date": date.strftime("%Y-%m-%d"),
                        "title": title.strip()
                    })
        
        return commits
    except subprocess.CalledProcessError as e:
        print(f"Error processing {repo_path}: {e}")
        return []

def group_commits_by_author(commits: list) -> list:
    """æŒ‰ä½œè€…åˆ†ç»„ commit"""
    author_commits = defaultdict(list)
    
    for commit in commits:
        author_commits[commit["author"]].append({
            "date": commit["date"],
            "title": commit["title"]
        })
    
    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œå¹¶æŒ‰æ—¥æœŸæ’åº
    result = []
    for author, commits_list in author_commits.items():
        sorted_commits = sorted(commits_list, key=lambda x: x["date"])
        result.append({
            "name": author,
            "commits": sorted_commits
        })
    
    # æŒ‰ commit æ•°é‡é™åºæ’åº
    result.sort(key=lambda x: len(x["commits"]), reverse=True)
    
    return result

def main():
    # è¯»å–ä»“åº“é…ç½®
    repos_json_path = Path("/Volumes/Files/se-practice/repos.json")
    with open(repos_json_path, 'r', encoding='utf-8') as f:
        repos = json.load(f)
    
    base_path = Path("/Volumes/Files/se-practice/repos")
    
    for repo_info in repos:
        group_num = repo_info["group_number"]
        repo_name = repo_info["repo_name"]
        branch = repo_info["git_branch"]
        
        # æ„å»ºä»“åº“è·¯å¾„
        repo_path = base_path / f"{group_num}-HospitalSystem" / repo_name
        
        if not repo_path.exists():
            print(f"âš ï¸  ä»“åº“ä¸å­˜åœ¨: {repo_path}")
            continue
        
        print(f"ğŸ“Š å¤„ç†ä»“åº“: {repo_name} (ç»„ {group_num}, åˆ†æ”¯ {branch})")
        
        # è·å– commits
        commits = get_commits(repo_path, branch)
        
        if not commits:
            print(f"   âš ï¸  æœªæ‰¾åˆ° commits")
            continue
        
        # æŒ‰ä½œè€…åˆ†ç»„
        contributors = group_commits_by_author(commits)
        
        # ä¿å­˜åˆ° JSON æ–‡ä»¶
        output_path = repo_path.parent / f"{repo_name}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(contributors, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… å·²ä¿å­˜ {len(contributors)} ä½è´¡çŒ®è€…çš„æ•°æ®åˆ° {output_path}")
        print(f"   ğŸ“ˆ æ€»è®¡ {len(commits)} ä¸ª commits")

if __name__ == "__main__":
    main()
